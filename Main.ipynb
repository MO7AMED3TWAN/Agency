{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3hAOYc9vt7g"
      },
      "outputs": [],
      "source": [
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from crewai.tools import tool\n",
        "from crewai.knowledge.source.string_knowledge_source import StringKnowledgeSource\n",
        "\n",
        "import agentops\n",
        "\n",
        "from tavily import TavilyClient\n",
        "# from scrapegraph_py import Client\n",
        "\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-pnTwyUBxoF5"
      },
      "outputs": [],
      "source": [
        "agentops.init(\n",
        "    api_key=\"7020e4de-5642-470e-8277-b6049dc6bf1e\",\n",
        "    skip_auto_end_session=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uu075ybyy1WI"
      },
      "outputs": [],
      "source": [
        "output_dir = \"./Outputs\"\n",
        "\n",
        "search_client = TavilyClient(api_key='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')\n",
        "# scrape_client = Client(api_key=userdata.get('scrapegraph'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup Agency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ----- Knowledge Base -----\n",
        "about_company = \"MAY-X automates market research and content creation using small language models (SLMs â‰¤3B). Local deployment ensures privacy and cost-efficiency.\"\n",
        "\n",
        "company_context = StringKnowledgeSource(\n",
        "    content=about_company, \n",
        "    description=\"MAY-X's SLM-powered AI agency services\"\n",
        "    )\n",
        "\n",
        "no_keywords = 5\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEeJqY2pznkZ"
      },
      "source": [
        "## Setup Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVAf4lJ28MbD"
      },
      "source": [
        "### Agent: Agent Searching"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0SavghHzpEV"
      },
      "outputs": [],
      "source": [
        "class SuggestedSearchQueries(BaseModel):\n",
        "    queries: List[str] = Field(..., title=\"Suggested search queries to be passed to the search engine\",\n",
        "                               min_items=1, max_items=no_keywords)\n",
        "\n",
        "search_queries_recommendation_agent = Agent(\n",
        "    role=\"Search Queries Recommendation Agent\",\n",
        "    goal=\"\\n\".join([\n",
        "                \"To provide a list of suggested search queries to be passed to the search engine.\",\n",
        "                \"The queries must be varied and looking for specific items.\"\n",
        "            ]),\n",
        "    backstory=\"The agent is designed to help in looking for products by providing a list of suggested search queries to be passed to the search engine based on the context provided.\",\n",
        "    llm=basic_llm,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "search_queries_recommendation_task = Task(\n",
        "    description=\"\\n\".join([\n",
        "        \"Rankyx is looking to buy {product_name} at the best prices (value for a price strategy)\",\n",
        "        \"The campany target any of these websites to buy from: {websites_list}\",\n",
        "        \"The company wants to reach all available proucts on the internet to be compared later in another stage.\",\n",
        "        \"The stores must sell the product in {country_name}\",\n",
        "        \"Generate at maximum {no_keywords} queries.\",\n",
        "        \"The search keywords must be in {language} language.\",\n",
        "        \"Search keywords must contains specific brands, types or technologies. Avoid general keywords.\",\n",
        "        \"The search query must reach an ecommerce webpage for product, and not a blog or listing page.\"\n",
        "    ]),\n",
        "    expected_output=\"A JSON object containing a list of suggested search queries.\",\n",
        "    output_json=SuggestedSearchQueries,\n",
        "    output_file=os.path.join(output_dir, \"step_1_suggested_search_queries.json\"),\n",
        "    agent=search_queries_recommendation_agent\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecrSUPhT-HmZ"
      },
      "source": [
        "### Agent: B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXtf-roZ-Jvz"
      },
      "outputs": [],
      "source": [
        "class SignleSearchResult(BaseModel):\n",
        "    title: str\n",
        "    url: str = Field(..., title=\"the page url\")\n",
        "    content: str\n",
        "    score: float\n",
        "    search_query: str\n",
        "\n",
        "class AllSearchResults(BaseModel):\n",
        "    results: List[SignleSearchResult]\n",
        "\n",
        "@tool\n",
        "def search_engine_tool(query: str):\n",
        "    \"\"\"Useful for search-based queries. Use this to find current information about any query related pages using a search engine\"\"\"\n",
        "    return search_client.search(query)\n",
        "\n",
        "search_engine_agent = Agent(\n",
        "    role=\"Search Engine Agent\",\n",
        "    goal=\"To search for products based on the suggested search query\",\n",
        "    backstory=\"The agent is designed to help in looking for products by searching for products based on the suggested search queries.\",\n",
        "    llm=basic_llm,\n",
        "    verbose=True,\n",
        "    tools=[search_engine_tool]\n",
        ")\n",
        "\n",
        "search_engine_task = Task(\n",
        "    description=\"\\n\".join([\n",
        "        \"The task is to search for products based on the suggested search queries.\",\n",
        "        \"You have to collect results from multiple search queries.\",\n",
        "        \"Ignore any susbicious links or not an ecommerce single product website link.\",\n",
        "        \"Ignore any search results with confidence score less than ({\n",
        "        }) .\",\n",
        "        \"The search results will be used to compare prices of products from different websites.\",\n",
        "    ]),\n",
        "    expected_output=\"A JSON object containing the search results.\",\n",
        "    output_json=AllSearchResults,\n",
        "    output_file=os.path.join(output_dir, \"step_2_search_results.json\"),\n",
        "    agent=search_engine_agent\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMjVBFl6YfFC"
      },
      "source": [
        "### Agent: C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejr-C8p2YgxT"
      },
      "outputs": [],
      "source": [
        "class ProductSpec(BaseModel):\n",
        "    specification_name: str\n",
        "    specification_value: str\n",
        "\n",
        "class SingleExtractedProduct(BaseModel):\n",
        "    page_url: str = Field(..., title=\"The original url of the product page\")\n",
        "    product_title: str = Field(..., title=\"The title of the product\")\n",
        "    product_image_url: str = Field(..., title=\"The url of the product image\")\n",
        "    product_url: str = Field(..., title=\"The url of the product\")\n",
        "    product_current_price: float = Field(..., title=\"The current price of the product\")\n",
        "    product_original_price: float = Field(title=\"The original price of the product before discount. Set to None if no discount\", default=None)\n",
        "    product_discount_percentage: float = Field(title=\"The discount percentage of the product. Set to None if no discount\", default=None)\n",
        "\n",
        "    product_specs: List[ProductSpec] = Field(..., title=\"The specifications of the product. Focus on the most important specs to compare.\", min_items=1, max_items=5)\n",
        "\n",
        "    agent_recommendation_rank: int = Field(..., title=\"The rank of the product to be considered in the final procurement report. (out of 5, Higher is Better) in the recommendation list ordering from the best to the worst\")\n",
        "    agent_recommendation_notes: List[str]  = Field(..., title=\"A set of notes why would you recommend or not recommend this product to the company, compared to other products.\")\n",
        "\n",
        "\n",
        "class AllExtractedProducts(BaseModel):\n",
        "    products: List[SingleExtractedProduct]\n",
        "\n",
        "\n",
        "@tool\n",
        "def web_scraping_tool(page_url: str):\n",
        "    \"\"\"\n",
        "    An AI Tool to help an agent to scrape a web page\n",
        "\n",
        "    Example:\n",
        "    web_scraping_tool(\n",
        "        page_url=\"https://www.noon.com/egypt-en/15-bar-fully-automatic-espresso-machine-1-8-l-1500\"\n",
        "    )\n",
        "    \"\"\"\n",
        "    details = scrape_client.smartscraper(\n",
        "        website_url=page_url,\n",
        "        user_prompt=\"Extract ```json\\n\" + SingleExtractedProduct.schema_json() + \"```\\n From the web page\"\n",
        "    )\n",
        "\n",
        "    return {\n",
        "        \"page_url\": page_url,\n",
        "        \"details\": details\n",
        "    }\n",
        "\n",
        "scraping_agent = Agent(\n",
        "    role=\"Web scraping agent\",\n",
        "    goal=\"To extract details from any website\",\n",
        "    backstory=\"The agent is designed to help in looking for required values from any website url. These details will be used to decide which best product to buy.\",\n",
        "    llm=basic_llm,\n",
        "    tools=[web_scraping_tool],\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "scraping_task = Task(\n",
        "    description=\"\\n\".join([\n",
        "        \"The task is to extract product details from any ecommerce store page url.\",\n",
        "        \"The task has to collect results from multiple pages urls.\",\n",
        "        \"Collect the best {top_recommendations_no} products from the search results.\",\n",
        "    ]),\n",
        "    expected_output=\"A JSON object containing products details\",\n",
        "    output_json=AllExtractedProducts,\n",
        "    output_file=os.path.join(output_dir, \"step_3_search_results.json\"),\n",
        "    agent=scraping_agent\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMQjc8eHgQd0"
      },
      "source": [
        "### Agent: D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joLe-Mr3gSNs"
      },
      "outputs": [],
      "source": [
        "procurement_report_author_agent = Agent(\n",
        "    role=\"Procurement Report Author Agent\",\n",
        "    goal=\"To generate a professional HTML page for the procurement report\",\n",
        "    backstory=\"The agent is designed to assist in generating a professional HTML page for the procurement report after looking into a list of products.\",\n",
        "    llm=basic_llm,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "procurement_report_author_task = Task(\n",
        "    description=\"\\n\".join([\n",
        "        \"The task is to generate a professional HTML page for the procurement report.\",\n",
        "        \"You have to use Bootstrap CSS framework for a better UI.\",\n",
        "        \"Use the provided context about the company to make a specialized report.\",\n",
        "        \"The report will include the search results and prices of products from different websites.\",\n",
        "        \"The report should be structured with the following sections:\",\n",
        "        \"1. Executive Summary: A brief overview of the procurement process and key findings.\",\n",
        "        \"2. Introduction: An introduction to the purpose and scope of the report.\",\n",
        "        \"3. Methodology: A description of the methods used to gather and compare prices.\",\n",
        "        \"4. Findings: Detailed comparison of prices from different websites, including tables and charts.\",\n",
        "        \"5. Analysis: An analysis of the findings, highlighting any significant trends or observations.\",\n",
        "        \"6. Recommendations: Suggestions for procurement based on the analysis.\",\n",
        "        \"7. Conclusion: A summary of the report and final thoughts.\",\n",
        "        \"8. Appendices: Any additional information, such as raw data or supplementary materials.\",\n",
        "    ]),\n",
        "\n",
        "    expected_output=\"A professional HTML page for the procurement report.\",\n",
        "    output_file=os.path.join(output_dir, \"step_4_procurement_report.html\"),\n",
        "    agent=procurement_report_author_agent,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JObrx_tu5mGd"
      },
      "source": [
        "## Run the AI Crew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFYBBb1W5oVp"
      },
      "outputs": [],
      "source": [
        "rankyx_crew = Crew(\n",
        "    agents=[\n",
        "        search_queries_recommendation_agent,\n",
        "        search_engine_agent,\n",
        "        scraping_agent,\n",
        "        procurement_report_author_agent,\n",
        "    ],\n",
        "    tasks=[\n",
        "        search_queries_recommendation_task,\n",
        "        search_engine_task,\n",
        "        scraping_task,\n",
        "        procurement_report_author_task,\n",
        "    ],\n",
        "    process=Process.sequential,\n",
        "    knowledge_sources=[company_context]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcQw4kcn6Gnj"
      },
      "outputs": [],
      "source": [
        "crew_results = rankyx_crew.kickoff(\n",
        "    inputs={\n",
        "        \"product_name\": \"coffee machine for the office\",\n",
        "        \"websites_list\": [\"www.amazon.eg\", \"www.jumia.com.eg\", \"www.noon.com/egypt-en\"],\n",
        "        \"country_name\": \"Egypt\",\n",
        "        \"no_keywords\": 10,\n",
        "        \"language\": \"English\",\n",
        "        \"score_th\": 0.10,\n",
        "        \"top_recommendations_no\": 10\n",
        "    }\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Agency",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
